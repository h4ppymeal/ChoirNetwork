{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create a new anaconda environment to manage libs and dependancies for this project, and name it choir_network `conda create -n choir_network python=3.9`\n",
    "- y when prompted\n",
    "- completely close VS code and reopen this folder (recents) - a refresh is needed\n",
    "- activate the environment `conda activate choir_network`\n",
    "- in the upper right corner, select the kernel for the notebook `select another > python envs > click on choir_network`\n",
    "- now conda install stuff. Run `conda install scikit-learn` in the terminal while you see `(choir_network)`, press `y` as needed.\n",
    "- run your code. If stuff asks to install `ipykernel package` stuff, just say yes\n",
    "- let's see if u can get past the matplotlib thingy using google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions\n",
    " 1. Process the Text\n",
    " - Convert to Lowercase\n",
    " - Remove Punctuation & Numbers\n",
    " - Tokenization (Splitting text into individual words or tokens)\n",
    " - Removing Stop Words (e.g. \"and\", \"the\", \"of\")\n",
    " - Stemming/Lemmatization (reducing words to their base/root form) *optional\n",
    "\n",
    " 2. Vectorize Text\n",
    " - Convert text into numerical format using TF-IDF or embeddings\n",
    " - TF-IDF weights the words based on their frequency in a document against their frequency across all documents\n",
    " - Word embeddings using Word2Vec, CloVe, or FastText can be used to convert words into vectors (better)\n",
    "\n",
    " 3. Dimensionality Reduction with t-SNE\n",
    " - Choosing parameters (starting point 5 - 50, learning rate 10-1000)\n",
    " - Scaling - Might need to scae feature vectors before applying (MinMAxScaler or StandardScaler)\n",
    " - Applying t-SNE to reduce dimensionality of vectorized hymns (from scikit-learn)\n",
    "\n",
    " 4. Visualization\n",
    " - Plotting (Matplotlib) to create a scatter plot of 2D points\n",
    " - Enhancements to make visualization more informative (optional?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import hymns\n",
    "hymns = []\n",
    "\n",
    "def get_hymns(): \n",
    "    h = input(\"Enter the hymn number (1-525). Press enter if finished. \")\n",
    "    if h:\n",
    "        hymns.append(int(h))\n",
    "        get_hymns()\n",
    "    else:\n",
    "        return hymns\n",
    "    \n",
    "get_hymns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Process the Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra example stuff\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits(n_class=6) # they have a built in dataset of numbers from 0 to n_class\n",
    "X, y = digits.data, digits.target # X is the data (image i believe), y is the correct value/label... I think\n",
    "n_samples, n_features = X.shape\n",
    "n_neighbors = 30 # inspect neighbourhood of nearest 30 points\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print out examples of data\n",
    "fig, axs = plt.subplots(nrows=10, ncols=10, figsize=(6, 6))\n",
    "for idx, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(X[idx].reshape((8, 8)), cmap=plt.cm.binary)\n",
    "    ax.axis(\"off\")\n",
    "_ = fig.suptitle(\"A selection from the 64-dimensional digits dataset\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a helper function to plot embeddings in a 2D space\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import offsetbox\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def plot_embedding(X, title):\n",
    "    _, ax = plt.subplots()\n",
    "    X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "    for digit in digits.target_names:\n",
    "        ax.scatter(\n",
    "            *X[y == digit].T,\n",
    "            marker=f\"${digit}$\",\n",
    "            s=60,\n",
    "            color=plt.cm.Dark2(digit),\n",
    "            alpha=0.425,\n",
    "            zorder=2,\n",
    "        )\n",
    "    shown_images = np.array([[1.0, 1.0]])  # just something big\n",
    "    for i in range(X.shape[0]):\n",
    "        # plot every digit on the embedding\n",
    "        # show an annotation box for a group of digits\n",
    "        dist = np.sum((X[i] - shown_images) ** 2, 1)\n",
    "        if np.min(dist) < 4e-3:\n",
    "            # don't show points that are too close\n",
    "            continue\n",
    "        shown_images = np.concatenate([shown_images, [X[i]]], axis=0)\n",
    "        imagebox = offsetbox.AnnotationBbox(\n",
    "            offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r), X[i]\n",
    "        )\n",
    "        imagebox.set(zorder=1)\n",
    "        ax.add_artist(imagebox)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this outlines a BUNCH of diff embedding space representations, TSNE is one of them, and you'll later see why it's the best one\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.manifold import (\n",
    "    MDS,\n",
    "    TSNE,\n",
    "    Isomap,\n",
    "    LocallyLinearEmbedding,\n",
    "    SpectralEmbedding,\n",
    ")\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "embeddings = {\n",
    "    \"Random projection embedding\": SparseRandomProjection(\n",
    "        n_components=2, random_state=42\n",
    "    ),\n",
    "    \"Truncated SVD embedding\": TruncatedSVD(n_components=2),\n",
    "    \"Linear Discriminant Analysis embedding\": LinearDiscriminantAnalysis(\n",
    "        n_components=2\n",
    "    ),\n",
    "    \"Isomap embedding\": Isomap(n_neighbors=n_neighbors, n_components=2),\n",
    "    \"Standard LLE embedding\": LocallyLinearEmbedding(\n",
    "        n_neighbors=n_neighbors, n_components=2, method=\"standard\"\n",
    "    ),\n",
    "    \"Modified LLE embedding\": LocallyLinearEmbedding(\n",
    "        n_neighbors=n_neighbors, n_components=2, method=\"modified\"\n",
    "    ),\n",
    "    \"Hessian LLE embedding\": LocallyLinearEmbedding(\n",
    "        n_neighbors=n_neighbors, n_components=2, method=\"hessian\"\n",
    "    ),\n",
    "    \"LTSA LLE embedding\": LocallyLinearEmbedding(\n",
    "        n_neighbors=n_neighbors, n_components=2, method=\"ltsa\"\n",
    "    ),\n",
    "    \"MDS embedding\": MDS(n_components=2, n_init=1, max_iter=120, n_jobs=2),\n",
    "    \"Random Trees embedding\": make_pipeline(\n",
    "        RandomTreesEmbedding(n_estimators=200, max_depth=5, random_state=0),\n",
    "        TruncatedSVD(n_components=2),\n",
    "    ),\n",
    "    \"Spectral embedding\": SpectralEmbedding(\n",
    "        n_components=2, random_state=0, eigen_solver=\"arpack\"\n",
    "    ),\n",
    "    \"t-SNE embedding\": TSNE(\n",
    "        n_components=2,\n",
    "        n_iter=500,\n",
    "        n_iter_without_progress=150,\n",
    "        n_jobs=2,\n",
    "        random_state=0,\n",
    "    ),\n",
    "    \"NCA embedding\": NeighborhoodComponentsAnalysis(\n",
    "        n_components=2, init=\"pca\", random_state=0\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run it\n",
    "\n",
    "from time import time\n",
    "\n",
    "projections, timing = {}, {}\n",
    "for name, transformer in embeddings.items():\n",
    "    if name.startswith(\"Linear Discriminant Analysis\"):\n",
    "        data = X.copy()\n",
    "        data.flat[:: X.shape[1] + 1] += 0.01  # Make X invertible\n",
    "    else:\n",
    "        data = X\n",
    "\n",
    "    print(f\"Computing {name}...\")\n",
    "    start_time = time()\n",
    "    projections[name] = transformer.fit_transform(data, y)\n",
    "    timing[name] = time() - start_time\n",
    "\n",
    "for name in timing:\n",
    "    title = f\"{name} (time {timing[name]:.3f}s)\"\n",
    "    plot_embedding(projections[name], title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hymn lyric section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius\n",
    "# you will want to run `pip install lyricsgenius` in your terminal,\n",
    "# again while you see (choir_network) so it means you are adding a library to this environment.\n",
    "# if pip doesn't work, you need to install pip to conda\n",
    "\n",
    "file_path = '/Users/markchen/Desktop/genius.txt' # replace this with wherever the file I gave you is\n",
    "token = \"x6BMSqzUa...\" # it is NEVER good to show api tokens in code.\n",
    "# In a workplace, it means security issues, and you'd get in trouble.\n",
    "\n",
    "# read the last line from the important file to get the token, without exposing it to github/public\n",
    "try:\n",
    "    with open(file_path, 'r') as file:\n",
    "        for i, line in enumerate(file, start=1):\n",
    "            if i == 6:\n",
    "                token = line.strip() # set the token as what is in the file, which will be used for the Genius API for lyrics\n",
    "                break\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file at {file_path} was not found.\")\n",
    "\n",
    "# function to get lyrics\n",
    "def get_hymn_lyrics(title):\n",
    "    genius = lyricsgenius.Genius(token)\n",
    "    song = genius.search_song(title)\n",
    "    if song:\n",
    "        print(song.lyrics)\n",
    "    else:\n",
    "        print(f\"No lyrics found for '{title}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hymn_title = \"Amazing Grace\"\n",
    "get_hymn_lyrics(hymn_title)\n",
    "# now let's see if we can just keep things simple, and clean/parse just for verse 1 of every hymn in titles.txt\n",
    "# Save it in a CSV i guess?\n",
    "# number,title,verse1,failed_or_not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "choir_network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
